{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a47616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from office365.runtime.auth.authentication_context import AuthenticationContext\n",
    "from office365.sharepoint.client_context import ClientContext\n",
    "from office365.sharepoint.files.file import File\n",
    "from office365.runtime.auth.client_credential import ClientCredential\n",
    "from office365.runtime.client_request_exception import ClientRequestException\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import glob\n",
    "import pyodbc\n",
    "import os \n",
    "import json\n",
    "from io import BytesIO\n",
    "import datetime\n",
    "import io\n",
    "import platform\n",
    "from PyToSp import *\n",
    "from TrackingFlatFile import *\n",
    "from GetProjectKey import *\n",
    "from utils import *\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff9f4b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-10-28 15:28:35.259328'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "my_date = datetime.datetime.now(pytz.timezone('Asia/Bangkok')).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "my_date = datetime.datetime.now(pytz.timezone('Asia/Bangkok')).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "my_date = datetime.datetime.now(pytz.timezone('Asia/Bangkok')).strftime(\"%Y-%m-%d %H:%M:%S.%f\")\n",
    "my_date = datetime.datetime.now(pytz.timezone('Asia/Bangkok')).strftime(\"%Y-%m-%d %H:%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f2e132",
   "metadata": {},
   "source": [
    "# Connect to SQL azure database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bddfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to SQL azure database\n",
    "# Credential\n",
    "\n",
    "server='hkazdevsqld3vnreserch.database.windows.net'\n",
    "database='D3VNResearch_Staging'\n",
    "username =  'D3VNResearch@savills.com.vn'\n",
    "password = '@Advisory092021!'\n",
    "auth = 'ActiveDirectoryPassword'\n",
    "#Connect SQL\n",
    "cnxn=pyodbc.connect(\"DRIVER={ODBC Driver 17 for SQL Server};SERVER=\"+server+\";DATABASE=\"+database+\";UID=\"+username+\";PWD=\"+password+\";Authentication=\"+auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98fd68e",
   "metadata": {},
   "source": [
    "# Connect to SharePoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9dca424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web site title: VN, BI - HCMC RS _ Successful Connection!\n"
     ]
    }
   ],
   "source": [
    "# Get authentication from json config file \n",
    "\n",
    "header_BIHub = 'share_point_BIHub'\n",
    "config_BIHub = read_config_json(config_path, header_BIHub) # config_path the same path with PyToSp module\n",
    "\n",
    "header_VNBIHNS = 'share_point_VNBIHNS'\n",
    "config_VNBIHNS = read_config_json(config_path, header_VNBIHNS) # config_path the same path with PyToSp module\n",
    "header_VNBIHCM='share_point_VNBIHCM'\n",
    "config_VNBIHCM=read_config_json(config_path, header_VNBIHCM)\n",
    "\n",
    "BIHub = SharePoint(config_BIHub)\n",
    "VNBIHNS = SharePoint(config_VNBIHNS)\n",
    "VNBIHCM=SharePoint(config_VNBIHCM)\n",
    "VNBIHCM.check_connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f8c2d7",
   "metadata": {},
   "source": [
    "# Run Audit Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e81cb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files name: /sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/SA_HN_20210930.csv\n",
      "Files name: /sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/Retail_HN_20210901_20211012.csv\n",
      "Files name: /sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/Office_HN_20210930_20211014.csv\n",
      "Files name: /sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/Retail_HN_20210901_20211012.xlsx\n",
      "Files name: /sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/Apartment_HN_20210930_20211012.csv\n",
      "Files name: /sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/Hotel_HN_20210930_20211014.csv\n",
      "Files name: /sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/VLTH_HN_20210930.csv\n"
     ]
    }
   ],
   "source": [
    "## Processing Folder\n",
    "relative_url = \"/sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3\"\n",
    "df_summ_file = VNBIHNS.get_content_url(relative_url)\n",
    "list_file = df_summ_file['ServerRelativeUrl'].to_list()\n",
    "df_query=pd.DataFrame(df_summ_file)\n",
    "data=pd.read_sql('select * from GENERAL.City_Dictionary',cnxn)\n",
    "Raw_City=dict(zip(data['Raw_City'],data['Cleaned_City']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51969be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass\n",
      "/sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/Office_HN_20210930_20211014.csv\n",
      "/sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/Retail_HN_20210901_20211012.xlsx\n",
      "/sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/Apartment_HN_20210930_20211012.csv\n",
      "/sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/Hotel_HN_20210930_20211014.csv\n",
      "/sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/SA_HN_20210930_20211012.xlsx\n",
      "/sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/VLTH_HN_20210901_20211014.csv\n"
     ]
    }
   ],
   "source": [
    "def Create_Audit(cnxn,Raw_City,list_file,df_query,obj_sp):\n",
    "    for file_url in list_file:\n",
    "        if file_url.split('/')[-1] in ['Retail_HN_20210901_20211012.csv']:\n",
    "            print(\"pass\")\n",
    "            pass\n",
    "        else:\n",
    "            crsr = cnxn.cursor()\n",
    "            summ(obj_sp, df_query, file_url,crsr,Raw_City)\n",
    "    cnxn.commit()\n",
    "    crsr.close()\n",
    "Create_Audit(cnxn,Raw_City,list_file,df_query,VNBIHNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4ff348d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-09-30 00:00:00')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data=VNBIHCM.get_file('/sites/VN-BI-HCMCRS/Shared Documents/HCMC RS/Flat input file/1. Main Sectors/2021/Q3/Office_HCMC_20210930.csv')\n",
    "#data=data.replace(r'\\* \\ *',np.nan)\n",
    "#data['retail.OCCUPANCY']=data['retail.OCCUPANCY'].astype(float)\n",
    "#data['retail.OCCUPANCY'][0:50]\n",
    "#data.loc[:,'retail.OCCUPANCY'].sum()\n",
    "#pd.to_datetime(data['office.DATE_KEY'].iloc[0],format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcd1189",
   "metadata": {},
   "source": [
    "# Get Project Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0cc5d685",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLTH_HN_20210930.csv\n",
      "Read csv with Encoding = cp1252 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████████████████████████████████████████            | 6/7 [00:00<00:00,  8.50it/s]\n"
     ]
    }
   ],
   "source": [
    "relative_url_upload = '/sites/BIHub/Shared Documents/Test'\n",
    "sql_query = \"SELECT * FROM GENERAL.City_Dictionary\"\n",
    "df_city_dict = pd.read_sql(sql_query,cnxn)\n",
    "save_to = '/Users/khoi/Desktop/test/'\n",
    "for file_url in tqdm(list_file):\n",
    "    if file_url.split('/')[-1] == 'Retail_HN_20210901_20211012.csv':\n",
    "        pass\n",
    "    elif file_url.split('/')[-1] == 'VLTH_HN_20210930.csv':\n",
    "#         Total_City=pd.read_sql('select * from GENERAL.City_Dictionary',cnxn)\n",
    "        # for file in csv_files:\n",
    "        print(file_url.split('/')[-1])\n",
    "        cursor=cnxn.cursor()\n",
    "        project_name=file_url.split('/')[-1]\n",
    "        format_file=project_name.split('.')[1]\n",
    "        Sector=file_url.split('/')[-1].upper().split('_')[0]\n",
    "        if Sector=='SA':\n",
    "            Sector='SERVICED_APARTMENT'\n",
    "        elif Sector=='APT':\n",
    "            Sector='APARTMENT'\n",
    "        Raw_City=file_url.split('/')[-1].upper().split('_')[1]\n",
    "        \n",
    "        ''' Modify Object Sharepoint here'''\n",
    "        data= VNBIHNS.get_file(file_url)\n",
    "        data=data.dropna(how='all')\n",
    "        data.columns=data.columns.str.strip()\n",
    "        if 'LATITUDE' and 'LONGITUDE' in data.columns:\n",
    "            data=data.rename(columns = {'LATITUDE':'LAT'})\n",
    "            data=data.rename(columns = {'LONGITUDE':'LONG'})\n",
    "        for i in list(data.columns):\n",
    "            data[i] = data[i].replace({np.nan: None})\n",
    "        data['location.CITY_NAME_DOC']=data[['location.CITY_NAME_DOC']].merge(df_city_dict,how='left',left_on=['location.CITY_NAME_DOC'], right_on=['Raw_City'])['Cleaned_City']\n",
    "        City = str(data['location.CITY_NAME_DOC'][1])\n",
    "        project_key=Project_key(City,Sector,cnxn)\n",
    "        data=Convert_District(data,cnxn)\n",
    "        if Sector=='VLTH' or Sector=='RETAIL':\n",
    "            project_key['SUB_PROJECT_TYPE']=project_key['SUB_PROJECT_TYPE'].str.strip()\n",
    "            data['project.SUB_PROJECT_TYPE']=data['project.SUB_PROJECT_TYPE'].str.strip()\n",
    "        #Xử lí LAT, LONG bị dấu (,)\n",
    "        data=Convert_Location(data,cnxn)\n",
    "        break\n",
    "        #Điền các values từ Project_Name nếu Sub_Project_Name NULL\n",
    "        data['project.ORIGINAL_SUB_PROJECT_NAME_DOC']=data['project.ORIGINAL_SUB_PROJECT_NAME_DOC'].fillna(data['project.PROJECT_NAME_DOC'])\n",
    "        data['project.PROJECT_NAME_DOC']=data['project.PROJECT_NAME_DOC'].fillna('project.ORIGINAL_SUB_PROJECT_NAME_DOC')\n",
    "        ##Loại bỏ space ở word\n",
    "        data['project.ORIGINAL_SUB_PROJECT_NAME_DOC']=data['project.ORIGINAL_SUB_PROJECT_NAME_DOC'].astype(str).str.strip()\n",
    "        #Left join 2 Dataframe\n",
    "        Merge_data=Merge(Sector,data,project_key)\n",
    "        #Lọc các Projectkey NULL\n",
    "        empty=Merge_data[Merge_data['PROJECT_KEY'].isna()]\n",
    "        #Convert LAUNCHING_TIME\n",
    "        empty=Convert_time(empty)\n",
    "        if empty.shape[0]!=0:\n",
    "#             Insert_DB(Sector,empty,cnxn,City)\n",
    "            Project_key_new=Project_key(City,Sector,cnxn)\n",
    "            result=Merge(Sector,data,Project_key_new)\n",
    "            data['project.PROJECT_KEY']=result['PROJECT_KEY']\n",
    "            project_name.split('.')[1]\n",
    "            data = data_cleaning(data, Sector)\n",
    "            # Insert data to sql database\n",
    "            insert_to_fact(data, Sector, cnxn)\n",
    "            \n",
    "            # Update file to sharepoint\n",
    "            filename = '{}.csv'.format(project_name.split('.')[0])\n",
    "            BIHub.upload_dataframe(relative_url_upload, data, filename)\n",
    "        else:\n",
    "            data['project.PROJECT_KEY']=Merge_data['PROJECT_KEY']\n",
    "            data = data_cleaning(data, Sector)\n",
    "            # Insert data to sql database\n",
    "            insert_to_fact(data, Sector, cnxn)\n",
    "            \n",
    "            # Update file to sharepoint\n",
    "            filename = '{}.csv'.format(project_name.split('.')[0])\n",
    "            BIHub.upload_dataframe(relative_url_upload, data, filename)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac96025c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv with Encoding = cp1252 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      21.019289\n",
       "1      21.018501\n",
       "2      21.018501\n",
       "3      21.028996\n",
       "4      21.028996\n",
       "         ...    \n",
       "503          NaN\n",
       "504          NaN\n",
       "505          NaN\n",
       "506          NaN\n",
       "507          NaN\n",
       "Name: LAT, Length: 508, dtype: float64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=VNBIHNS.get_file('/sites/VN-BI-HNRS/Shared Documents/HN RS/Flat input file/1. Main Sectors/2021/Q3/VLTH_HN_20210930.csv')\n",
    "data['LAT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb375992",
   "metadata": {},
   "source": [
    "# Upload to SharePoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0d1e274",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8be37755443e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrelative_url_upload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/sites/BIHub/Shared Documents/Test'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Office_HN_20210930_20211014.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mBIHub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelative_url_upload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/PyToSp/PyToSp.py\u001b[0m in \u001b[0;36mupload_dataframe\u001b[0;34m(self, file_url, dataframe, filename)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mdataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"UTF-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Write the dataframe to the buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/A2DS/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[1;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3169\u001b[0m         )\n\u001b[0;32m-> 3170\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/A2DS/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m             )\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/A2DS/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/A2DS/lib/python3.7/site-packages/pandas/io/formats/csvs.py\u001b[0m in \u001b[0;36m_save_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_mi_columns\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhas_aliases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mencoded_labels\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;31m# write out the mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "# from io import BytesIO\n",
    "relative_url_upload = '/sites/BIHub/Shared Documents/Test'\n",
    "filename = 'Office_HN_20210930_20211014.csv'\n",
    "BIHub.upload_dataframe(relative_url_upload, data, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6eb426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
